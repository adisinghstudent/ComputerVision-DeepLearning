{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess the MNIST dataset.\n",
    "\n",
    "    Returns:\n",
    "        X_train (np.ndarray): Training features.\n",
    "        y_train (np.ndarray): One-hot encoded training labels.\n",
    "        X_test (np.ndarray): Test features.\n",
    "        y_test (np.ndarray): One-hot encoded test labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True)\n",
    "    test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "    # Convert data to float32 and normalize by dividing by 255\n",
    "    X_train = train_dataset.data.numpy().astype(\"float32\") / 255\n",
    "    y_train = train_dataset.targets.numpy()\n",
    "    X_test = test_dataset.data.numpy().astype(\"float32\") / 255\n",
    "    y_test = test_dataset.targets.numpy()\n",
    "\n",
    "    # Reshape each image (28x28) to a flat vector (784,)\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # One-hot encoding for labels\n",
    "    y_train = np.eye(10)[y_train]\n",
    "    y_test = np.eye(10)[y_test]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a simple neural network using numpy and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Softmax activation function that converts logits into probabilities.\n",
    "\n",
    "    Args:\n",
    "        z (np.ndarray): The input logits of shape (N, K), \n",
    "                        where N is the number of samples and K is the number of classes.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output probabilities of shape (N, K), \n",
    "                    where each row contains the class probabilities for a sample.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z)  # Exponentiate each logit (element-wise)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)  # Normalize along classes (axis=1)\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions.\n",
    "\n",
    "    Args:\n",
    "        y_pred (np.ndarray): Predicted probabilities of shape (N, K), \n",
    "                             where N is the number of samples and K is the number of classes.\n",
    "        y (np.ndarray): True labels of shape (N, K), one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the predictions, a scalar between 0 and 1.\n",
    "    \"\"\"\n",
    "    predictions = np.argmax(y_pred, axis=1)  # Class with the highest probability for each sample\n",
    "    true_labels = np.argmax(y, axis=1)  # Ground truth class for each sample\n",
    "    return np.mean(predictions == true_labels)  # Fraction of correct predictions\n",
    "\n",
    "\n",
    "def cross_entropy_loss(A, y):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss between predicted probabilities and true labels.\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): Predicted probabilities of shape (N, K), \n",
    "                        where N is the number of samples and K is the number of classes.\n",
    "        y (np.ndarray): True labels of shape (N, K), one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        float: The average cross-entropy loss across all samples.\n",
    "    \"\"\"\n",
    "    m = y.shape[0]  # Number of samples\n",
    "    loss = -np.sum(y * np.log(A)) / m  # Average cross-entropy loss\n",
    "    return loss\n",
    "\n",
    "    #change for main\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with random weights and zero biases.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features (e.g., 784 for 28x28 MNIST images).\n",
    "            output_size (int): Number of output classes (e.g., 10 for MNIST digits).\n",
    "\n",
    "        Attributes:\n",
    "            W (np.ndarray): Weight matrix of shape (input_size, output_size), \n",
    "                            initialized randomly.\n",
    "            b (np.ndarray): Bias vector of shape (1, output_size), initialized to zeros.\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.W = np.random.rand(input_size, output_size)\n",
    "        self.b = np.zeros((1, self.output_size))\n",
    "\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        Perform the forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Input features of shape (N, input_size), \n",
    "                            where N is the number of samples.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The output probabilities of shape (N, output_size), \n",
    "                        where each row contains the class probabilities for a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert X.shape[1] == self.input_size, \"Input feature size mismatch\"\n",
    "        \n",
    "        # TODO: Implement this function using equation 1 from the task description\n",
    "        # Tips: Use the softmax function on the logits (z_k)\n",
    "        # Replace this line!\n",
    "        y_hat = np.zeros((X.shape[0],self.output_size))\n",
    "        #######################\n",
    "\n",
    "        assert y_hat.shape[0] == X.shape[0], \"Output batch size mismatch\"\n",
    "        assert y_hat.shape[1] == self.output_size, \"Output class size mismatch\"\n",
    "        return y_hat\n",
    "    \n",
    "\n",
    "\n",
    "    def backward_pass(self, X, y, y_hat):\n",
    "        \"\"\"\n",
    "        Perform the backward pass to compute gradients for weights and biases.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Input features of shape (N, input_size).\n",
    "            y (np.ndarray): True labels of shape (N, output_size), one-hot encoded.\n",
    "            y_hat (np.ndarray): Predicted probabilities of shape (N, output_size).\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - dW (np.ndarray): Gradient of the loss with respect to weights, \n",
    "                                   of shape (input_size, output_size).\n",
    "                - db (np.ndarray): Gradient of the loss with respect to biases, \n",
    "                                   of shape (1, output_size).\n",
    "        \"\"\"\n",
    "\n",
    "        assert X.shape[1] == self.input_size, \"Input feature size mismatch\"\n",
    "        assert y.shape == y_hat.shape, \"True and predicted label shapes must match\"\n",
    "        \n",
    "        # TODO: Implement this function using equation 4 and 5\n",
    "        # Replace these lines!\n",
    "        dW = self.W\n",
    "        db = self.b\n",
    "        #######################\n",
    "\n",
    "        assert dW.shape == self.W.shape, \"Weight gradient shape mismatch\"\n",
    "        assert db.shape == self.b.shape, \"Bias gradient shape mismatch\"\n",
    "        return dW, db\n",
    "\n",
    "\n",
    "    def update_parameters(self, dW, db, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the parameters of the model using gradient descent.\n",
    "\n",
    "        Args:\n",
    "            dW (np.ndarray): Gradient of the loss with respect to weights, \n",
    "                             of shape (input_size, output_size).\n",
    "            db (np.ndarray): Gradient of the loss with respect to biases, \n",
    "                             of shape (1, output_size).\n",
    "            learning_rate (float): The learning rate for gradient descent.\n",
    "\n",
    "        Updates:\n",
    "            self.W: Updated weight matrix.\n",
    "            self.b: Updated bias vector.\n",
    "        \"\"\"\n",
    "        assert dW.shape == self.W.shape, \"Weight gradient shape mismatch in update\"\n",
    "        assert db.shape == self.b.shape, \"Bias gradient shape mismatch in update\"\n",
    "        \n",
    "        # TODO: Implement this function using equation 6\n",
    "        # Replace these lines!\n",
    "        self.W = self.W # Update weights\n",
    "        self.b = self.b # Update biases\n",
    "        #######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 2/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 3/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 4/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 5/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 6/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 7/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 8/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 9/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Epoch 10/10, Train Accuracy: 0.0987, Loss: nan\n",
      "Test Accuracy: 0.0980, Test Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/kvgz6hbs39j9_tq6xbrmn27m0000gn/T/ipykernel_33329/1291285792.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(y * np.log(A)) / m  # Average cross-entropy loss\n",
      "/var/folders/3n/kvgz6hbs39j9_tq6xbrmn27m0000gn/T/ipykernel_33329/1291285792.py:47: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(y * np.log(A)) / m  # Average cross-entropy loss\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9000)\n",
    "\n",
    "# Load data\n",
    "X_train, y_train, X_test, y_test = load_mnist_data()\n",
    "\n",
    "#changes made for adibranch \n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 10  # Number of classes (digits 0-9)\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "net = NeuralNetwork(input_size, output_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0  # Initialize loss for this epoch\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "        y_hat = net.forward_pass(X_batch)\n",
    "        epoch_loss += cross_entropy_loss(y_hat, y_batch)\n",
    "        dW, db = net.backward_pass(X_batch, y_batch, y_hat)\n",
    "        net.update_parameters(dW, db, learning_rate)\n",
    "        \n",
    "    epoch_loss /= (X_train.shape[0] / batch_size)\n",
    "    logits = net.forward_pass(X_train)\n",
    "    train_accuracy = calculate_accuracy(y_pred=logits, y=y_train)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Test set accuracy:\n",
    "logits = net.forward_pass(X_test)\n",
    "test_accuracy = calculate_accuracy(y_pred=logits, y=y_test)\n",
    "test_loss = cross_entropy_loss(logits, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference on test set using trained model\n",
    "\n",
    "This code block selects a random sample from the test set and performs inference. Re-run this block to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'True Label: 2, Predicted Label: 0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "random_index = np.random.randint(0, high=len(X_test), size=None, dtype=int)\n",
    "x = X_test[random_index][None]\n",
    "y = np.argmax(y_test[random_index])\n",
    "\n",
    "y_hat = net.forward_pass(x)\n",
    "pred = np.argmax(y_hat)\n",
    "\n",
    "plt.imshow(x.reshape([28,28]))\n",
    "plt.title(f\"True Label: {y}, Predicted Label: {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
